# 矩阵乘法（矩阵 * 矩阵，矩阵 * 向量）
M * a = b有两种理解方式，
## 第一种: 同一个向量的坐标变换
将M视为一个全新独立坐标系，a是某个向量在这个坐标系的分量，b则是同一个向量在笛卡尔坐标系的读数

斜角坐标系（由M确定）中的向量读数(x,y),表示它是基向量g1的x倍，g2的y倍，分别计算后，得到两个向量
的笛卡尔读数，再由向量加法，得到这个向量的笛卡尔读数

### 做坐标变换的两种方法。
两种方法本质相同，都是利用矩阵乘法行乘以列的特点，将斜角坐标读数，分别乘以两个基向量，
然后再相加。向量的加法容易理解。不多讲。

如果以基向量的笛卡尔读数作为行，那就要把行向量放左边，乘以这个矩阵，得到行向量。
```
(x,y) * g1x g1y  = x[g1x,g1y]  
        g2x g2y   +y[g2x,g2y]   
```
如果把基向量的笛卡尔读数作为列，就要把列向量放右边，乘以这个矩阵，得到列向量
```
g1x g2x * x  = x * g1x + y* g2x
g1y g2y   y        g1y      g2y
```
我觉得这个方法更简单、直观，容易理解。向量和坐标系都是静态的，比较好思考。
### 对矩阵连乘的理解
M * M1 * v    
可以这样理解。矩阵M1的两列，是两个向量在M中的读数。和M乘一次，就得到了这两个基向量的笛卡尔读数。
向量v，是M1中的读数, 整个算式的结果，则是v在笛卡尔坐标系的读数。

如果左侧有更多矩阵，依然用这个方法理解。  
M0 * M * M1 * v   
最终就是为了求M1的两列的笛卡尔读数。v的读数由两个基向量（M1的两列）决定，但这两个基向量的读数
不是笛卡尔读数，是M中的读数。而M坐标系的读数又是M0坐标系的，只有M0的两列才是笛卡尔读数。
连乘之后，才能得到M1的笛卡尔读数。进而可以求出v的笛卡尔读数。

而逆矩阵的连乘，就是将笛卡尔读数，转换成最后面这个坐标系的读数。
用multple_matrix_times.py可以验证这两个想法。确实如此。
## 第二种：对坐标系变形，向量随坐标系变形
将M视为对笛卡尔坐标系的变形。也就是《线性代数的本质》中的方法。
a是笛卡尔坐标系下的某个向量。b是这个向量随着基向量变形（也就是整个坐标系的变形）后
得到的向量（a,b的读数都是笛卡尔读数）

这种理解也许对理解逆矩阵有好处。
### 矩阵与矩阵相乘
矩阵相乘，按线性代数的本质，可以理解为两次变换，相继作用于基向量（这样被乘数就可以不写了）。这个是好理解的。
那么度量张量可以认为是连续作用于i,j的两个矩阵相乘的结果。与第一个矩阵相乘，得知i,j分别去了什么地方
```
e, g
f, h
然后再用另一个矩阵
a c
b d
与这个矩阵相乘，那么接下来i到了这个位置
a  * e  + c * f
b         d

即基向量i最终的位置是
a*e+c*f
b*e+d*f
基向量j的最终位置是
ag+ch
bg+dh 
```

这个还是可以用第一种方法，即坐标变换而不是对基向量的变形来理解。
两个矩阵连乘，得到一个最终的新的斜角坐标系。
这个矩阵再和一个向量相乘，就又回到了矩阵与向量乘法的定义，即被乘向量是一个向量在这个
斜角坐标系的读数，结果是这个向量的笛卡尔读数。

用整个系统的变形理解有个好处就是可以连续操作。用基向量来理解，不容易想清楚连续操作。

但是以连续变形来理解坐标变换有点费劲。因为矩阵相乘有连续性，所以两个矩阵相乘的结果，
乘以某个向量，这个读数是这个结果矩阵中的读数，不是相乘的两个矩阵中的任何一个的读数。
# G, G.I、G.dual、度量张量 以及它们之间的关系
这个概念之间的几何联系是什么样子的？
## G 
### 定义
以两个基向量的笛卡尔读数为列构成的矩阵，
### 作用
可以将斜角坐标系的读数转换成笛卡尔读数
### 理解方式，本质
将G理解成变形矩阵，还不如将它理解为一个独立的绘制在
笛卡尔坐标系中的另外一个坐标系。变形有点麻烦。

利用前面矩阵乘法作为坐标变换的解释，很容易理解G的本质和作用。
## G.I 即G的逆矩阵
### 作用
将向量的笛卡尔读数转换成斜角坐标系的读数， 

或者说，将被斜角坐标系变形的向量变回原来的样子。

### 理解方式
同G

## M 度量张量
度量张量如果作为中间工具，好理解，但它本身有没有几何意义？
### 作用
- 最重要的作用：将向量斜角坐标读数的点乘，转换成笛卡尔点乘。
```
(x,y) @ G.T @ G (x, y).T
```
- 将斜角坐标转换到它的对对偶坐标系（即指标升降）。为什么它能够将斜角坐标读数，转换成对偶坐标系的读数？
这是个代数巧合，还是有几何原因？要看看对偶坐标系的定义，和逆矩阵的定义。

参见后面的证明。
### 公式
- 第一个公式好理解。就是一个中间量。先分别将斜角坐标读数转换成笛卡尔读数，再点乘
```
G.T@G
```

这个其实理解为凑答案也可以。

```
最原始的定义，来源于求一个向量的笛卡尔长度。
就是先把斜角读数转换成笛卡尔读数再矩阵乘（向量有个特点，点乘和矩阵乘结果相同。）
因为矩阵运算不能交换，但结合是可以的。所以下面的式子中间不能写成点乘，而要写成矩阵乘
即
G@(x,y) @ G@(x,y)

但这样没办法独立的保存两个G。不方便抽取为一个新的独立的东西形成公式，方便以后运算
利用前面讲到的矩阵乘法的两种方法，可以这样写

(x,y) @ G.T @ G @(x,y).T

作为斜角坐标系下面的长度公式。
把G.T @ G定义成度量张量。方便以后运算 
```
- 第二个
```
g1@g1 g1@g2
g2@g1 g1@g1
``` 
其实这和第一个是一回事。G.T， 就是第一行是g1,第二行是g2。那么G.T@G,就可以写成
```
g1x g1y      g1x  g2x
g2x g2y   *  g1y  g2y 

注意，乘号两边是两个矩阵，那么按照矩阵乘法就是
(g1x,g1y) @ (g1x,g1y), (g1x,g1y) @ (g2x,g2y)
(g2x,g2y) @ (g1x,g1y), (g2x,g2y) @ (g2x,g2y)
即
g1@g1, g1@g2
g2@g1, g2@g2 
```

## G.dual G的对偶矩阵，对偶坐标系
还是不明白前人为什么要定义对偶坐标系。度量张量用不上对偶坐标系
对偶坐标系是个先被发现，然后玩坏的工具，还是有意被设计出来，陆续
发现更多用法的？ 

对偶基矢量、对偶坐标系到底有什么作用？是怎么想到这个鬼东西的？
对偶基矢量组在张量分析中的作用与意义  
http://www.docin.com/p-776933043.html

对偶这个概念还不能乱用呢？因为还有对偶空间的概念。  
https://baike.baidu.com/item/%E5%AF%B9%E5%81%B6%E7%A9%BA%E9%97%B4

但逆变协变的概念更不好。我到底也没看出来怎么逆变怎么协变。

这个文章看起来比较容易理解，算是讲得比较透彻的。但还是没完全懂  
http://blog.sciencenet.cn/home.php?mod=space&uid=583426&do=blog&id=1135202
https://zhuanlan.zhihu.com/p/73196097
### 定义和公式
```
gd1 @ g1 = gd2 @ g2 = 1
gd1 @ g2 = gd2 @ g1 = 0

G.I.T
这个公式有个应用，因为G用来把斜角读数转化成笛卡尔读数，那么, G的逆矩阵
可以用来将笛卡尔读数转换成斜角读数。即
v_o = G_dual.T @ v_c 
或者，
v_o = v_c @ G_dual

数学真是被玩坏了的东西，有些东西并不是那么直观，前人一点一点的凑出来
或者试出来，后人直接拿来就用，越搞越脱离直观。
```
### 作用
- 一个向量的斜角读数与它的对偶坐标系的读数的点乘（且借用逆变和协变分量这个说法）的结果，
与笛卡尔读数得到的长度(x平方+y平方)的平方一致

这看起来是一种修正作用。但现在没找到严格表述。

https://zhuanlan.zhihu.com/p/43792297
向量是逆变的，对偶向量是协变的， 于是向量和对偶向量所合成的双线性变换是不随基而变化的
怎么说明双线性变换是不变的？ 什么是双线性变换
```
如果一个向量，在两个坐标系中的读数分别是
(gd1*x1,gd2*y1) (g1*x,g2*y)

那么向量的自乘（是一个向量在两个坐标系的读数自乘）=
gd1*g1*x1*x + gd2*g2*y1*y
因为
gd1*g1=1
gd2*g2=1
所以上面的算式可以化简成x1*x+y1*y，

看起来x1*x+y1*y构成了某个直角三角形的两个边的平方。但这个直角三角形在哪个坐标轴上？
```

### 为什么对偶坐标系 = G.I.T 
```
将gd1,gd2, g1, g2分别用笛卡尔读数表示，则对偶坐标系的定义
gd1 @ g1 = gd2 @ g2 = 1
gd1 @ g2 = gd2 @ g1 = 0

将上面的关系用矩阵乘法表示(注意，第一个矩阵是以两个基向量为行，即G.T，第二个则是以基向量为列，即G
这么做只是为了利用矩阵乘法表示上面的定义)，即

gd1x gd1y  * g1x g2x = I (单位矩阵) 
gd2x gd2y    g1y g2y

计算这个矩阵乘法，得到下面的结果, 符合对偶坐标系基向量的定义
gd1x*g1x+gd1y*g1y=gd1@g1=1   gd1x*g2x+gd1y*g2y=gd1@g2=0
gd2x*g1x+gd2y*g1y=gd2@g1=0   gd2x*g2x+gd2y*g2y=gd2@g2=1

所以对偶坐标系就是G的逆矩阵的转置。

要能从向量乘法中看出矩阵乘法，没这个直觉，不行就多试几次吧。
```
### 为什么度量张量可以做指标升降？
用矩阵连乘来理解度量张量的指标升降作用更好吧？
v_d = m @ v_o = G.T @ G @ v_o

但是，为什么会想出来要在G.T里面定义G?这个还是有点扯

还有这个对偶性，是不是真的存在？ 度量张量看起来就像是做了两次很类似的变换。
像是不变一样。似是而非的理解。还不行。
```
v_d = m @ v_o = G.T @ G @ v_o = G.dual.I @ v_c

前面已经证明下面几点 
G.dual = G.I.T(参见前面的证明)， 
v_c = G @ v_o,(用矩阵乘法即可理解) 
v_d = G.dual.I @ v_c(用矩阵乘法即可理解)

从这几点开始推导上面的关系式
将v_c用v_o表示
v_d = G.dual.I @ G @ v_o

因为G.dual = G.I.T(前面已经证明)
所以G.dual.I = G.I.T.I
因为G.T.I = G.I.T
    严格证明在这里：https://www.zhihu.com/question/53736888

所以G.I.T.I = G.T.I.I = G.T 
所以G.dual.I = G.T 
所以 v_d = G.T @ G @ v_o
    = m @ v_o
```
# 逆矩阵
## 逆矩阵的几何意义
逆矩阵的几何意义，也可说是消除坐标变形

只有逆矩阵，没有逆向量。逆矩阵是对斜角坐标系的基向量的反向操作，如果g1在x方向放大a倍，逆矩阵则缩小a倍，
如果基向量移动了x轴，则逆矩阵要讲x轴移动回去。

通过变形理解逆矩阵容易，通过坐标变换，有点费劲儿。
## 逆矩阵和矩阵除法
感觉逆矩阵就是矩阵的除法。一个算式除以某个矩阵，等价于它乘以这个矩阵的逆矩阵。
## 求逆矩阵的方法
但逆矩阵的运算颇为复杂，因为你对一个基向量的一个分量的变动，还会影响另一个基向量的分量，所以不是直接修改基向量的分量那么简单。

可以这样理解逆矩阵的运算：根据M * a = I * b，可以想象，求M的逆矩阵，就是尝试对I变形，即

M-1 * M * a = M-1 * I * b

即当a = M-1 * I * b 的时候，就找到了M的逆矩阵M-1。这相当于对b的坐标系也就是单位矩阵变形，然后记录这个变形。

这样更容易，因为对笛卡尔坐标系的变形进行追踪比对斜角坐标系进行追踪容易多了。

这个情况下逆矩阵的求结果过程也许可以变成解方程组。但似乎对于第一种理解，通过勾股定理猛算就能得出逆矩阵。把两个基向量缩放旋转回i、j就可以了？
但各处的资料显示不是这么简单。


# 行列式和以及逆矩阵的计算
行列式的本质就是坐标系变形时，单位矩形i*j的面积的变化倍数。行列式的公式，看来只是一个巧合。  
![行列式](images/det.png)

但它为什么和逆矩阵有关系？下面的文章讲得很好！但涉及了伴随矩阵和代数与余子式
https://www.zhihu.com/question/301361922 

### 伴随矩阵和代数余子式
是什么东西？  
https://www.shuxuele.com/algebra/matrix-inverse-minors-cofactors-adjugate.html

代数余子式、行列式、伴随矩阵、逆矩阵这几个东西，有什么神秘的内在联系呢？

怎么能直观的找到逆矩阵？如果能找到，就犯不上琢磨行列式、伴随矩阵、代数余子式这几个东西。

逆矩阵的几何意义倒是足够容易理解。不过计算真是好麻烦。

理解怎么把一个斜角坐标系变形回笛卡尔坐标系，这个事情还挺麻烦的。比把笛卡尔坐标系变形成斜角坐标系麻烦多了。
后者只需要以斜角坐标系的两个基向量的笛卡尔坐标读数为列，写出一个矩阵就行了。

# 并矢
这个东西确实成立，但却不能让我很好的理解。
